{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjusting Miner Scoring in the Bittensor Subnet: Climate Zone Analysis  \n",
    "\n",
    "## Introduction  \n",
    "\n",
    "In this notebook, we aim to lay the groundwork for implementing a climate-based reward function in the Bittensor subnet. This involves mapping grid locations to climate types, analyzing prediction difficulty for each climate zone, and setting up the framework for dynamic reward adjustments.  \n",
    "\n",
    "### The Reward Function  \n",
    "\n",
    "The reward function we use to evaluate miner performance is defined as:  \n",
    "\n",
    "$$\n",
    "\\text{Reward} = \\max\\left(0, \\frac{z - \\text{RMSE}}{z}\\right)\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- \\( z \\): A value that defines the acceptable error margin for a given task.  \n",
    "- \\( \\text{RMSE} \\): The root mean squared error of the miner’s prediction compared to the ground truth.  \n",
    "\n",
    "This reward function works as follows:  \n",
    "- If the miner's prediction is perfect (\\( \\text{RMSE} = 0 \\)), the reward is 1 (maximum reward).  \n",
    "- As the \\( \\text{RMSE} \\) increases, the reward decreases proportionally.  \n",
    "- If \\( \\text{RMSE} \\) exceeds \\( z \\), the reward becomes 0, incentivizing miners to improve their predictions.  \n",
    "\n",
    "### Why Adjust \\( z \\) Values?  \n",
    "\n",
    "The \\( z \\) value is crucial because it sets the threshold for acceptable error. A higher \\( z \\) makes the task easier by allowing more error, while a lower \\( z \\) makes it harder by narrowing the acceptable margin for error.  \n",
    "\n",
    "Since climate prediction difficulty varies by region:  \n",
    "- **Easy Regions**: For example, predicting temperature over large, stable oceans may have low variability, making it easier to forecast accurately. Here, a lower \\( z \\) value can be used.  \n",
    "- **Challenging Regions**: Areas like mountains or deserts with significant temperature fluctuations are more difficult to predict. For these regions, a higher z value would compensate for that, while lowering \\( z \\) encourages miners to invest more effort and resources into improving accuracy. So we can play with that.\n",
    "\n",
    "### Initially: Using SOTA Models to Calibrate \\( z \\)  \n",
    "\n",
    "To ensure the reward function reflects realistic difficulty levels:  \n",
    "1. We use a state-of-the-art (SOTA) AI climate forecasting model to compute the average RMSE for each climate type.  \n",
    "2. The observed RMSE values will guide the initial \\( z \\) values, ensuring that rewards align with the inherent difficulty of predicting each climate zone.  \n",
    "3. Over time, \\( z \\) values can be manually adjusted to focus efforts on regions where improved predictions provide the most value.  \n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, we will:  \n",
    "1. Visualize the Köppen-Geiger climate zones to understand the diversity of climate types.  \n",
    "2. Create a grid-based dictionary for efficient climate type lookup.  \n",
    "3. Use a SOTA climate forecasting model to evaluate RMSE for each climate zone.  \n",
    "4. Define initial \\( z \\) values based on the SOTA model’s performance.  \n",
    "\n",
    "This step-by-step process ensures a fair, data-driven approach to incentivizing accurate climate forecasting in the Bittensor subnet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Köppen-Geiger Climate Zones  \n",
    "\n",
    "The Köppen-Geiger climate classification system is a widely used method for categorizing global climates based on observed temperature, precipitation, and seasonal patterns. It divides the Earth's surface into distinct climate types, each with a unique combination of letters to denote characteristics such as temperature range, humidity levels, and seasonal behavior.  \n",
    "\n",
    "![Köppen-Geiger Climate Map](../images/Koeppen-Geiger-climate-classification.jpg \"Köppen-Geiger Climate Zones Map\")  \n",
    "\n",
    "### Key Features of the Classification System:  \n",
    "1. **Primary Categories**: The first letter represents the major climate group:  \n",
    "   - **A**: Tropical  \n",
    "   - **B**: Dry  \n",
    "   - **C**: Temperate  \n",
    "   - **D**: Cold  \n",
    "   - **E**: Polar  \n",
    "\n",
    "2. **Secondary Categories**: The second letter adds details about precipitation patterns:  \n",
    "   - **f**: Fully humid  \n",
    "   - **w**: Winter dry season  \n",
    "   - **s**: Summer dry season  \n",
    "   - **m**: Monsoonal  \n",
    "\n",
    "3. **Tertiary Categories**: The third letter describes temperature variations:  \n",
    "   - **a**: Hot summer  \n",
    "   - **b**: Warm summer  \n",
    "   - **c**: Cool summer  \n",
    "   - **d**: Extremely cold winter  \n",
    "   - **h**: Hot arid  \n",
    "   - **k**: Cold arid  \n",
    "\n",
    "### Climate Classes as a Basis for \\( z \\) Values  \n",
    "\n",
    "In this notebook, we will use all the climate classes visualized in the Köppen-Geiger map as the basis for defining \\( z \\) values. Each class will have its own \\( z \\) value, reflecting the prediction difficulty for that climate type. For example:  \n",
    "- **Cfa (Warm temperate, fully humid, hot summer)**: Found in large parts of the southeastern United States, this region is moderately challenging to predict and might have an initial \\( z = 3 \\).  \n",
    "- **Dfb (Cold, fully humid, warm summer)**: Found in much of Canada and northern Europe, this zone might require a slightly higher \\( z \\) due to greater variability.  \n",
    "\n",
    "### Visualization and Climate Zones  \n",
    "\n",
    "A visualization of the Köppen-Geiger climate zones will help us understand the spatial distribution of these classifications. For regions without documented climate data, such as some parts of the oceans, we will assign an **UNKNOWN** class. This ensures comprehensive coverage and enables predictions across all areas of interest.  \n",
    "\n",
    "### Setting \\( z \\) Values  \n",
    "\n",
    "The exact \\( z \\) values for each climate type will be calculated later in this notebook, using a SOTA climate forecasting model to establish a baseline RMSE for each class. These \\( z \\) values will ensure that rewards in the Bittensor subnet are appropriately scaled to reflect the inherent difficulty of making accurate predictions in each climate zone.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a grid-based dictionary for efficient climate type lookup.  \n",
    "Since the data source that we will use contain a grid with some pin points on the earth of locations in terms of lat lon with 0.25 degree steps we will create a dictionary lookup where we can see for each of these points on earth what the corresponding climates are. we will start by showing an example of a datapoint from ERA5 (a grid with corresponding tempratures) and then we will "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique latitude and longitude points:\n",
      "[(-74.75, -164.75), (-74.75, -164.5), (-74.75, -164.25), (-74.75, -164.0), (-74.75, -163.75), (-74.75, -163.5), (-74.75, -163.25), (-74.75, -163.0), (-74.75, -162.75), (-74.75, -162.5), (-74.75, -162.25), (-74.75, -162.0), (-74.75, -161.75), (-74.5, -164.75), (-74.5, -164.5), (-74.5, -164.25), (-74.5, -164.0), (-74.5, -163.75), (-74.5, -163.5), (-74.5, -163.25), (-74.5, -163.0), (-74.5, -162.75), (-74.5, -162.5), (-74.5, -162.25), (-74.5, -162.0), (-74.5, -161.75), (-74.25, -164.75), (-74.25, -164.5), (-74.25, -164.25), (-74.25, -164.0), (-74.25, -163.75), (-74.25, -163.5), (-74.25, -163.25), (-74.25, -163.0), (-74.25, -162.75), (-74.25, -162.5), (-74.25, -162.25), (-74.25, -162.0), (-74.25, -161.75), (-74.0, -164.75), (-74.0, -164.5), (-74.0, -164.25), (-74.0, -164.0), (-74.0, -163.75), (-74.0, -163.5), (-74.0, -163.25), (-74.0, -163.0), (-74.0, -162.75), (-74.0, -162.5), (-74.0, -162.25), (-74.0, -162.0), (-74.0, -161.75), (-73.75, -164.75), (-73.75, -164.5), (-73.75, -164.25), (-73.75, -164.0), (-73.75, -163.75), (-73.75, -163.5), (-73.75, -163.25), (-73.75, -163.0), (-73.75, -162.75), (-73.75, -162.5), (-73.75, -162.25), (-73.75, -162.0), (-73.75, -161.75), (-73.5, -164.75), (-73.5, -164.5), (-73.5, -164.25), (-73.5, -164.0), (-73.5, -163.75), (-73.5, -163.5), (-73.5, -163.25), (-73.5, -163.0), (-73.5, -162.75), (-73.5, -162.5), (-73.5, -162.25), (-73.5, -162.0), (-73.5, -161.75), (-73.25, -164.75), (-73.25, -164.5), (-73.25, -164.25), (-73.25, -164.0), (-73.25, -163.75), (-73.25, -163.5), (-73.25, -163.25), (-73.25, -163.0), (-73.25, -162.75), (-73.25, -162.5), (-73.25, -162.25), (-73.25, -162.0), (-73.25, -161.75), (-73.0, -164.75), (-73.0, -164.5), (-73.0, -164.25), (-73.0, -164.0), (-73.0, -163.75), (-73.0, -163.5), (-73.0, -163.25), (-73.0, -163.0), (-73.0, -162.75), (-73.0, -162.5), (-73.0, -162.25), (-73.0, -162.0), (-73.0, -161.75), (-72.75, -164.75), (-72.75, -164.5), (-72.75, -164.25), (-72.75, -164.0), (-72.75, -163.75), (-72.75, -163.5), (-72.75, -163.25), (-72.75, -163.0), (-72.75, -162.75), (-72.75, -162.5), (-72.75, -162.25), (-72.75, -162.0), (-72.75, -161.75), (-72.5, -164.75), (-72.5, -164.5), (-72.5, -164.25), (-72.5, -164.0), (-72.5, -163.75), (-72.5, -163.5), (-72.5, -163.25), (-72.5, -163.0), (-72.5, -162.75), (-72.5, -162.5), (-72.5, -162.25), (-72.5, -162.0), (-72.5, -161.75), (-72.25, -164.75), (-72.25, -164.5), (-72.25, -164.25), (-72.25, -164.0), (-72.25, -163.75), (-72.25, -163.5), (-72.25, -163.25), (-72.25, -163.0), (-72.25, -162.75), (-72.25, -162.5), (-72.25, -162.25), (-72.25, -162.0), (-72.25, -161.75), (-72.0, -164.75), (-72.0, -164.5), (-72.0, -164.25), (-72.0, -164.0), (-72.0, -163.75), (-72.0, -163.5), (-72.0, -163.25), (-72.0, -163.0), (-72.0, -162.75), (-72.0, -162.5), (-72.0, -162.25), (-72.0, -162.0), (-72.0, -161.75), (-71.75, -164.75), (-71.75, -164.5), (-71.75, -164.25), (-71.75, -164.0), (-71.75, -163.75), (-71.75, -163.5), (-71.75, -163.25), (-71.75, -163.0), (-71.75, -162.75), (-71.75, -162.5), (-71.75, -162.25), (-71.75, -162.0), (-71.75, -161.75), (-71.5, -164.75), (-71.5, -164.5), (-71.5, -164.25), (-71.5, -164.0), (-71.5, -163.75), (-71.5, -163.5), (-71.5, -163.25), (-71.5, -163.0), (-71.5, -162.75), (-71.5, -162.5), (-71.5, -162.25), (-71.5, -162.0), (-71.5, -161.75), (-71.25, -164.75), (-71.25, -164.5), (-71.25, -164.25), (-71.25, -164.0), (-71.25, -163.75), (-71.25, -163.5), (-71.25, -163.25), (-71.25, -163.0), (-71.25, -162.75), (-71.25, -162.5), (-71.25, -162.25), (-71.25, -162.0), (-71.25, -161.75), (-71.0, -164.75), (-71.0, -164.5), (-71.0, -164.25), (-71.0, -164.0), (-71.0, -163.75), (-71.0, -163.5), (-71.0, -163.25), (-71.0, -163.0), (-71.0, -162.75), (-71.0, -162.5), (-71.0, -162.25), (-71.0, -162.0), (-71.0, -161.75)]\n"
     ]
    }
   ],
   "source": [
    "# lets show a simple example of a datapoint\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from climate.data.era5_loader import ERA5DataLoader\n",
    "import numpy as np\n",
    "\n",
    "x = ERA5DataLoader()\n",
    "\n",
    "lat_start = np.random.uniform(x.lat_range[0], x.lat_range[1] - x.area_sample_range[1])\n",
    "lat_end = lat_start + np.random.uniform(*x.area_sample_range)\n",
    "lon_start = np.random.uniform(x.lon_range[0], x.lon_range[1] - x.area_sample_range[1])\n",
    "lon_end = lon_start + np.random.uniform(*x.area_sample_range)\n",
    "\n",
    "start_time, end_time, predict_hours = x._sample_time_range()\n",
    "\n",
    "data = x.get_data(\n",
    "    lat_start=lat_start, \n",
    "    lat_end=lat_end, \n",
    "    lon_start=lon_start, \n",
    "    lon_end=lon_end, \n",
    "    start_time=start_time, \n",
    "    end_time=end_time\n",
    ")\n",
    "\n",
    "# Extract latitude and longitude\n",
    "lat_lon_points = data[..., :2]  # Select only the latitude and longitude\n",
    "unique_lat_lon = lat_lon_points.view(-1, 2).unique(dim=0)  # Flatten and get unique points\n",
    "\n",
    "# Convert to a list of tuples if desired\n",
    "unique_lat_lon_list = [tuple(point.tolist()) for point in unique_lat_lon]\n",
    "\n",
    "print(\"Unique latitude and longitude points:\")\n",
    "print(unique_lat_lon_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the latitude and longitude points are spaced 0.25 degrees apart, so we will need to create a climate dictionary for each pair of latitude and longitude, with a 0.25-degree interval between the points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 92416 climate data points.\n"
     ]
    }
   ],
   "source": [
    "def load_koeppen_geiger_data(file_path=\"/root/ClimateAI/climate/data/Koeppen-Geiger-ASCII.txt\"):\n",
    "    \"\"\"Load climate data from the Koeppen-Geiger-ASCII.txt file into a dictionary.\"\"\"\n",
    "    all_lats = np.arange(-89.75, 90.25, 0.5)\n",
    "    all_lons = np.arange(-179.75, 180.25, 0.5)\n",
    "    climate_data = dict()\n",
    "    for lat in all_lats:\n",
    "        for lon in all_lons:\n",
    "            if float(lat) not in climate_data:\n",
    "                climate_data[float(lat)] = {}\n",
    "\n",
    "            # initially set all classes to UNKNOWN\n",
    "            climate_data[float(lat)][float(lon)] = \"UNKNOWN\"  \n",
    "\n",
    "    counter = 0\n",
    "    \n",
    "    with open(file_path, \"r\") as file:\n",
    "        # Skip the header\n",
    "        next(file)\n",
    "        \n",
    "        # Process each line in the file\n",
    "        for line in file:\n",
    "            parts = line.split()\n",
    "            if len(parts) == 3:  # Ensure valid data line\n",
    "                lat, lon, cls = parts\n",
    "                lat = float(lat)\n",
    "                lon = float(lon)\n",
    "\n",
    "                # Update the climate class\n",
    "                climate_data[lat][lon] = cls\n",
    "                counter += 1\n",
    "\n",
    "    print(f\"Loaded {counter} climate data points.\")\n",
    "    return climate_data\n",
    "\n",
    "koeppen_geiger_data = load_koeppen_geiger_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-89.75, -89.25, -88.75, -88.25, -87.75]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(koeppen_geiger_data.keys())[:5]  # Show the first 5 keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Köppen-Geiger data from this source is initially provided with a grid resolution of 0.5 degrees. To increase the resolution to 0.25 degrees and make it suitable for our use case, we will generate a new Köppen-Geiger grid with 0.25-degree intervals. For each new point in this refined grid, we will assign the climate class based on the most frequent class found in the surrounding area. The following Python code can help achieve this by interpolating the original grid data to a finer resolution and assigning the dominant class within the neighborhood of each new point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def refine_grid(original_grid, step=0.25):\n",
    "    \"\"\"\n",
    "    Refine a grid to a finer resolution with interpolation.\n",
    "    \n",
    "    Args:\n",
    "        original_grid (dict): Original grid as a dictionary of dictionaries.\n",
    "        step (float): Step size for the new grid.\n",
    "    \n",
    "    Returns:\n",
    "        dict: New dictionary with refined grid.\n",
    "    \"\"\"\n",
    "    def combine_values(weights, values):\n",
    "        \"\"\"Combine values proportionally based on weights.\"\"\"\n",
    "        counts = defaultdict(float)\n",
    "        for weight, value in zip(weights, values):\n",
    "            counts[value] += weight\n",
    "        return max(counts, key=counts.get)  # Return the value with the highest weight\n",
    "    \n",
    "    # Extract keys and create a new grid range\n",
    "    keys = sorted(original_grid.keys())\n",
    "    new_keys = [round(i * step, 2) for i in range(int(keys[0] / step), int(keys[-1] / step) + 1)]\n",
    "    \n",
    "    # Initialize the refined grid\n",
    "    refined_grid = defaultdict(dict)\n",
    "    \n",
    "    # Interpolate for each row and column\n",
    "    for y in new_keys:\n",
    "        for x in new_keys:\n",
    "            # Find surrounding keys\n",
    "            y0 = max([k for k in keys if k <= y], default=min(keys))\n",
    "            y1 = min([k for k in keys if k >= y], default=max(keys))\n",
    "            x0 = max([k for k in keys if k <= x], default=min(keys))\n",
    "            x1 = min([k for k in keys if k >= x], default=max(keys))\n",
    "\n",
    "            # Get weights for interpolation\n",
    "            wy0 = 1 - (y - y0) / (y1 - y0) if y1 != y0 else 1\n",
    "            wy1 = 1 - wy0\n",
    "            wx0 = 1 - (x - x0) / (x1 - x0) if x1 != x0 else 1\n",
    "            wx1 = 1 - wx0\n",
    "\n",
    "            # Collect surrounding values and weights\n",
    "            weights = [wy0 * wx0, wy0 * wx1, wy1 * wx0, wy1 * wx1]\n",
    "            values = [\n",
    "                original_grid[y0][x0], original_grid[y0][x1],\n",
    "                original_grid[y1][x0], original_grid[y1][x1]\n",
    "            ]\n",
    "\n",
    "            # Compute the combined value\n",
    "            refined_grid[y][x] = combine_values(weights, values)\n",
    "    \n",
    "    # Convert defaultdict to a standard dictionary\n",
    "    return {k: dict(v) for k, v in refined_grid.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "koeppen_grid_025 = refine_grid(koeppen_geiger_data, step=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"../data/koeppen_geiger_climate_grid_025.pkl\", \"wb\") as f:\n",
    "    pickle.dump(x, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
